{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ZEUSBOT DOCUMENTATION PORTAL","text":"<p> Development of an autonomous robotic system for image acquisition. Specifically, the system detects a target object based on a given reference point, navigates toward it, and then maintains a stable distance from the object of interest. Using a robotic arm, the camera is positioned at multiple viewpoints around the object to achieve better coverage. Subsequently, a 3D reconstruction of the object is performed based on the captured images. </p> <p> </p> <p> </p>"},{"location":"Gazebo/Object_insertion/","title":"Object Insertion","text":"<p> To import a new 3D object (.obj) into Gazebo, first create a model folder inside ~/.gazebo/models/ (e.g. ~/.gazebo/models/object1). Inside this folder, add subdirectories materials/textures and materials/scripts, where you place the texture image (.jpg or .png). In the main folder, include the object files (object1.obj and object1.mtl). Then create two files: model.config, which contains basic model information (name, description, author), and model.sdf, where you define the geometry using model://object1/object1.obj and specify whether the object is static (true) or movable (false). After saving, open Gazebo and from Insert \u2192 Model you can select and place your new object into the simulation world. </p>"},{"location":"Gazebo/World_creation/","title":"World creation","text":""},{"location":"Gazebo/World_creation/#install-gazebo","title":"Install Gazebo","text":"<ol> <li>Open the terminal and type:</li> </ol> <pre><code>sudo apt install ros-humble-gazebo-*\n</code></pre> <p>Close and reopen the terminal</p>"},{"location":"Gazebo/World_creation/#gazibo-world","title":"Gazibo world","text":"<ol> <li> <p>To launch it, type gazebo. In Insert, there\u2019s Add Path. At http://models.gazebosim.org/  you can find ready-made Gazebo models.</p> </li> <li> <p>To create walls: Edit \u2192 Building Editor. Draw the walls, and to save: File \u2192 Save As (Ctrl+Shift+S) \u2192 enter the name and where to save \u2192 Save \u2192 Exit (in the next window).</p> </li> <li> <p>To save the world: File \u2192 Save World As \u2192 enter the name (name.world) and location \u2192 Save.</p> </li> </ol> <p>To open the world you created, you need to be in the folder where you saved it (hercules@hercules:~/gazebo_examples$) and type in the terminal:</p> <pre><code>gazebo (name.world)\n</code></pre>"},{"location":"UGV_with_robotic_arm/control_arm/","title":"Arm Control","text":"<p> I have developed a code that allows me to control the joints of the robotic arm. Through this implementation, each joint can be individually adjusted, enabling precise manipulation of the arm\u2019s position and orientation. This functionality is essential for performing tasks such as object handling, image acquisition, or calibration within the robotic system. </p>"},{"location":"UGV_with_robotic_arm/control_arm/#steps","title":"Steps","text":"<p> Inside the folder `my_robot_description`, open two terminal windows. In the first terminal, execute the following commands: </p> <pre><code>source install/setup.bash\n</code></pre> <p>after</p> <pre><code>ros2 launch my_robot_bringup my_robot_gazebo.launch.xml \n</code></pre> <p>Then, in the second terminal, run:</p> <pre><code>source install/setup.bash\n</code></pre> <p>after</p> <pre><code>python3 arm_control2.py\n</code></pre> <p> </p>"},{"location":"UGV_with_robotic_arm/control_ugv/","title":"UGV Control","text":"<p> The robot can also be controlled directly from the PC using keyboard input. This allows the operator to manually navigate or adjust the robot\u2019s position in real time, providing an intuitive and straightforward way to interact with the system during testing or demonstration. </p>"},{"location":"UGV_with_robotic_arm/control_ugv/#steps","title":"Steps","text":"<p> Inside the folder `my_robot_description`, open two terminal windows. In the first terminal, execute the following commands: </p> <pre><code>source install/setup.bash\n</code></pre> <p>after</p> <pre><code>ros2 launch my_robot_bringup my_robot_gazebo.launch.xml \n</code></pre> <p>Then, in the second terminal, run:</p> <pre><code>source install/setup.bash\n</code></pre> <p>after</p> <pre><code>ros2 run teleop_twist_keyboard teleop_twist_keyboard \n</code></pre> <p> </p>"},{"location":"deployment/3D_reconstruction/","title":"3D Reconstruction","text":"<p> A 3D reconstruction of the object is then carried out using the captured images. Advanced photogrammetry tools such as COLMAP or RealityCapture are employed to generate a precise and detailed digital model of the object. </p>"},{"location":"deployment/3D_reconstruction/#result","title":"Result","text":""},{"location":"deployment/Data_collection/","title":"Data Collection","text":"<p> The robot maintains a stable distance from the object of interest to ensure optimal visibility and positioning. Using a robotic arm, the camera is moved to multiple viewpoints around the object, capturing images from different angles. This multi-perspective acquisition allows for better coverage and enhances the accuracy of the 3D reconstruction process. </p>"},{"location":"deployment/Data_collection/#steps","title":"Steps","text":"<p> Inside the folder `my_robot_description`, open two terminal windows. In the first terminal, execute the following commands: </p> <pre><code>source install/setup.bash\n</code></pre> <p>after</p> <pre><code>ros2 launch my_robot_bringup my_robot_gazebo.launch.xml \n</code></pre> <p>Then, in the second terminal, run:</p> <pre><code>source install/setup.bash\n</code></pre> <p>after</p> <pre><code>ros2 run robot_controller go_with_arm\n</code></pre> <p> </p>"},{"location":"deployment/Object_detection/","title":"Object detection","text":"<p> With the aid of a visual marker and the `RANSAC` method, the robot is able to detect and localize the target object in its environment. Once the object\u2019s position is estimated, the robot autonomously navigates toward it, continuously refining its trajectory based on the detected marker. When it reaches the predefined distance set by the user, the robot stops and maintains a stable position, ensuring accurate alignment with the object for subsequent tasks such as inspection or image acquisition. </p>"},{"location":"deployment/Object_detection/#steps","title":"Steps","text":"<p> Inside the folder `my_robot_description`, open two terminal windows. In the first terminal, execute the following commands: </p> <pre><code>source install/setup.bash\n</code></pre> <p>after</p> <pre><code>ros2 launch my_robot_bringup my_robot_gazebo.launch.xml \n</code></pre> <p>Then, in the second terminal, run:</p> <pre><code>source install/setup.bash\n</code></pre> <p>after</p> <pre><code>ros2 run robot_controller qr\n</code></pre> <p>or </p> <pre><code>ros2 run robot_controller marker_kalo\n</code></pre> <p> </p>"},{"location":"deployment/Object_detection/#ransac-3d-and-marker-based-detection","title":"RANSAC-3D and marker-based detection","text":"<p> Inside the folder `my_robot_description`, open two terminal windows. In the first terminal, execute the following commands: </p> <p> </p> <pre><code>source install/setup.bash\n</code></pre> <p>after</p> <pre><code>ros2 launch my_robot_bringup my_robot_gazebo.launch.xml \n</code></pre> <p>Then, in the second terminal, run:</p> <pre><code>source install/setup.bash\n</code></pre> <p>after</p> <pre><code>ros2 run robot_controller ransac\n</code></pre> <p>      Your browser does not support the video tag.    </p>"},{"location":"deployment/installation_basic/","title":"Basic Installation","text":""},{"location":"deployment/installation_basic/#basic-installation","title":"Basic Installation","text":""},{"location":"deployment/installation_basic/#step-1","title":"Step 1","text":"<p> The first step is to install ROS 2. This can be done inside a Docker container, providing an isolated and reproducible environment for development. </p> <p> </p>"},{"location":"deployment/installation_basic/#step-2","title":"Step 2","text":"<p> Download a copy of the robotic system package from [GitHub](https://github.com/TEXTaiLES/Robotics/tree/main/my_robot_description) or get the zip archive. If you\u2019re not familiar with git, don\u2019t worry \u2014 just download the zip file and extract it somewhere on your computer. However, the best approach is to git clone the repository, as this allows you to periodically update your installation without affecting your custom configurations. </p> <p>To clone the repository using the terminal, run:</p> <pre><code>git clone https://github.com/TEXTaiLES/Robotics.git\n</code></pre>"},{"location":"deployment/installation_basic/#step-3","title":"Step 3","text":"<p> After the installation is complete, navigate to the `my_robot_description` folder, and inside it, execute the following commands: </p> <pre><code>colcon build\ncolcon build --symlink-install\n</code></pre>"},{"location":"deployment/installation_basic/#step-4","title":"Step 4","text":"<p>To enable image processing capabilities, install OpenCV and the ROS 2 bridge package by running the following commands in the terminal:</p> <pre><code>pip install opencv-python\n</code></pre> <p>then</p> <pre><code>sudo apt install ros-humble-cv-bridge\n</code></pre> <p> </p>"},{"location":"deployment/installation_basic/#step-5","title":"Step 5","text":"<p> Inside the `my_robot_description` directory, source the workspace by running: </p> <pre><code>source install/setup.bash\n</code></pre> <p> Then, launch the simulation with: </p> <pre><code>ros2 launch my_robot_bringup my_robot_gazebo.launch.xml\n</code></pre> <p> This will start Gazebo and load the robot into its virtual environment. </p> <p> </p>"}]}